{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#import modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import integrate\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures,OrdinalEncoder, OneHotEncoder\nfrom sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn import set_config\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": "#Import the data\nvehicles = pd.read_csv(\"data/vehicles.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "It's now time to clean and prepare the data. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Count the number of NaN across the different columns, and format as a percent\nnan_percent = (vehicles.isna().sum() / len(vehicles) * 100).apply(lambda x: f\"{x:.3g}%\")\nprint(nan_percent)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "id                  0%\nregion              0%\nprice               0%\nyear            0.282%\nmanufacturer     4.13%\nmodel            1.24%\ncondition        40.8%\ncylinders        41.6%\nfuel            0.706%\nodometer         1.03%\ntitle_status     1.93%\ntransmission    0.599%\nVIN              37.7%\ndrive            30.6%\nsize             71.8%\ntype             21.8%\npaint_color      30.5%\nstate               0%\ndtype: object\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "The data above shows the % of each column that is NaN. In order to clean this data I will take the following steps:\n1) drop size column, since nearly 3/4 of the data is missing\n2) drop VIN column, since there is a high % missing data, and the series number is unlikely to provide helpful prediction without the ability to interpret it\n3) drop the cylinders, drive, and type columns. Although this data could potentially be filled in with the rest of the data provided (likely should be s\necificed by Manufacturer and Model), it's outisde the scope of this project. So for maximization of clean data I am dropping these columns as well. \n4) drop columns paint color and condition, as they have too much missing data. Future work could be done including condition, which I woudl expect to be an extremely strong predictor of price, but dropping it would lose nearly 50% of the rows. \n5)drop ID coluymn, since it doesn't contain any data, and I prefer to use the default index which starts at one\n6) remove the rows with missing data in year, manufacturer, model, odometer, title_status, transmission, fuel since they are all likely helpful data, and the cost to the dataset is minimal\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "vehicles_clean = vehicles.drop(columns=['size','VIN', 'cylinders', 'type', 'drive','condition','paint_color','id'])\nvehicles_clean = vehicles_clean.dropna(subset=['year','manufacturer','model','odometer','title_status','transmission','fuel'])\n\n#nan_percent_clean = (vehicles_clean.isna().sum() / len(vehicles_clean) * 100).apply(lambda x: f\"{x:.3g}%\")\n#print(nan_percent_clean)\nprint(vehicles_clean.info())\nprint(\"\")\nprint('Cleaning this data set removed ', len(vehicles)-len(vehicles_clean), ' rows, or ',  \"{:.3g}\".format((len(vehicles)-len(vehicles_clean))/len(vehicles)*100 ), '% of the total rows')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 389604 entries, 27 to 426879\nData columns (total 10 columns):\n #   Column        Non-Null Count   Dtype  \n---  ------        --------------   -----  \n 0   region        389604 non-null  object \n 1   price         389604 non-null  int64  \n 2   year          389604 non-null  float64\n 3   manufacturer  389604 non-null  object \n 4   model         389604 non-null  object \n 5   fuel          389604 non-null  object \n 6   odometer      389604 non-null  float64\n 7   title_status  389604 non-null  object \n 8   transmission  389604 non-null  object \n 9   state         389604 non-null  object \ndtypes: float64(2), int64(1), object(7)\nmemory usage: 22.3+ MB\nNone\n\nCleaning this data set removed  37276  rows, or  8.73 % of the total rows\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "Now that I have cleaned the data, it is time to further organize the data, by one-hot encoding the cateogircal variables.\n\nFurther investigation showed that some of these columns had ery high numbers of unique values. state has 51 unique values, and region has 404,  model has 21860, and manufacturer. All of these contain potentially extremely useful information, and could be useful. In order to minimize the process times, I'm choosing to drop region and model, and keep manufacturer and state. It is worth noting, that a car dealership in a particular state might benefit from dropping data from all other states, and investigating the differences in region. Similarly, a dealership that specializes in a specific manufacturer might drop all other manufactures, and look deeper into the models. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## dropping valid data due to too many categorical variables\nvehicle_clean_one_hot = vehicles_clean.drop(columns=['region', 'model'])\n\n#onehot-encode the remaining categorical rows:\nvehicle_clean_one_hot = pd.get_dummies(vehicle_clean_one_hot)\n\n# Identify the non-one-hot encoded columns\nnon_one_hot_columns = ['price', 'year', 'odometer']\n\n# Mean-center the non-one-hot encoded columns\nvehicle_clean_one_hot[non_one_hot_columns] = vehicle_clean_one_hot[non_one_hot_columns].apply(lambda x: x - x.mean())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "#seperate data into x and y sets\nvehicle_y = vehicle_clean_one_hot['price']\nvehicle_X = vehicle_clean_one_hot.drop(columns='price')\n\n#seperate into train and test sets\nvehicle_X_train, vehicle_X_test, vehicle_y_train, vehicle_y_test = train_test_split(vehicle_X, vehicle_y, test_size = 0.3, random_state = 42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "### GRADED\nselector = ''\nXt = ''\n\n### BEGIN SOLUTION\nselector = SequentialFeatureSelector(estimator=LinearRegression(),\n                                    n_features_to_select=4,\n                                    scoring = 'neg_mean_squared_error')\nXt = selector.fit_transform(vehicle_X_train, vehicle_y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "selected_features_mask = selector.get_support()\n\n# Get the list of selected feature names\nselected_features = vehicle_X_train.columns[selected_features_mask]\n\nprint(\"Selected Features:\", selected_features)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Selected Features: Index(['year', 'manufacturer_mercedes-benz', 'state_ca', 'state_va'], dtype='object')\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "The interpretation of this, is that the top influences on price are year, and then whether the manufacturer is mercedes-benz and whether the state is either CA or VA. This intuitively makes sense, as mercedez-benz is a luxury brand, and CA and VA are high cost of living states. However, it doesn't give us much information as a prospective dealership attempting to predict price.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "*** Approach 2***\n\nSince there is so much data, I am going to prepare the data for a very different approach",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "vehicles_ca = vehicles[vehicles['state'] == 'ca']\n\nvehicles_num = vehicles_ca.drop(columns=['size','VIN', 'drive','paint_color','id','transmission','fuel','region','manufacturer','model','state'])\nvehicles_num = vehicles_num.dropna(subset=['year','cylinders','odometer','condition','type','title_status'])\n\nprint('Cleaning this data set removed ', len(vehicles)-len(vehicles_num), ' rows, or ',  \"{:.3g}\".format((len(vehicles)-len(vehicles_num))/len(vehicles)*100 ), '% of the total rows')\n\n#seperate data into x and y sets\nvehicle_y = vehicles_num['price']\nvehicle_X = vehicles_num.drop(columns='price')\nvehicle_X_train, vehicle_X_test, vehicle_y_train, vehicle_y_test = train_test_split(vehicle_X, vehicle_y, test_size = 0.3, random_state = 42)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Cleaning this data set removed  407812  rows, or  95.5 % of the total rows\n         year  condition    cylinders  odometer title_status    type\n31143  2011.0  excellent  6 cylinders  139000.0        clean   sedan\n58949  2019.0       good  8 cylinders    9220.0        clean  pickup\n55359  2001.0       good  8 cylinders  272041.0        clean   sedan\n54019  2006.0       good  6 cylinders  106000.0        clean   sedan\n53668  2006.0  excellent  4 cylinders   61800.0        clean   sedan\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 50
    },
    {
      "cell_type": "code",
      "source": "# step 1: differentiate categorical and numerical features\ncategorical_features = ['condition', 'cylinders','title_status','type']  # categorical feature names for one-hot encoding\nnumerical_features = ['year','odometer']  # numerical feature names for standardization\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 62
    },
    {
      "cell_type": "code",
      "source": "# prepare pre-processoring to encode one-hot the categorical features, and scalte the numerical features. \npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(), categorical_features),\n        ('num', StandardScaler(), numerical_features)\n    ])\n\n# Step 3: Create a pipeline with preprocessing and Lasso regression\nlasso_pipe = Pipeline([\n    ('preprocessor', preprocessor),\n    ('lasso', Lasso(random_state=42))\n])\n\n# Step 4: Define the parameter grid for GridSearchCV\nparam_grid = {'lasso__alpha': [1, 10, 100,1000]}\nlasso_grid_search = GridSearchCV(lasso_pipe, param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n\n# Step 5: Fit the GridSearchCV on the training data\nlasso_grid_search.fit(vehicle_X_train, vehicle_y_train)\n\n# Step 6: Evaluate the model on the test data\nlasso_best_model = lasso_grid_search.best_estimator_\ny_pred = lasso_best_model.predict(vehicle_X_test)\nlasso_mse = mean_squared_error(vehicle_y_test, y_pred)\nlasso_r2 = r2_score(vehicle_y_test, y_pred)\n\nprint(f\"Mean Squared Error: {lasso_mse}\")\nprint(f\"R^2 Score: {lasso_r2}\")\nbest_alpha = best_params['lasso__alpha']\nprint(f\"Best Alpha for Lasso: {best_alpha}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error: 215786573932395.12\nR^2 Score: -0.0001600810826447585\nBest Alpha for Lasso: 10\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": "ridge_pipe = Pipeline([\n    ('preprocessor', preprocessor),\n    ('ridge', Ridge(random_state=42))\n])\n\nparam_grid = {\n    'ridge__alpha': [0.1, 1, 10, 100, 1000]  # Example values; adjust as needed\n}\n\n# Define GridSearchCV\nridge_grid_search = GridSearchCV(ridge_pipe, param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n\nridge_grid_search.fit(vehicle_X_train, vehicle_y_train)\n\n# Get the best model\nridge_best_model = ridge_grid_search.best_estimator_\n\n# Get the best parameters\nridge_best_params = ridge_grid_search.best_params_\n\n# Predict on the test set\ny_pred = ridge_best_model.predict(vehicle_X_test)\n\n# Evaluate the model\nmse = mean_squared_error(vehicle_y_test, y_pred)\nr2 = r2_score(vehicle_y_test, y_pred)\n\nprint(f\"Mean Squared Error of Best Ridge Model: {mse}\")\nprint(f\"R^2 Score of Best Ridge Model: {r2}\")\nprint(f\"Ridge Best Parameters: {ridge_best_params}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error of Best Ridge Model: 215786540680561.03\nR^2 Score of Best Ridge Model: -0.00015992696204070178\nRidge Best Parameters: {'ridge__alpha': 1}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 82
    },
    {
      "cell_type": "markdown",
      "source": "Ridge Model outperforms the Lasso model, due to having a lower MSE.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Extract the preprocessor and Ridge model from the pipeline\npreprocessor = ridge_best_model.named_steps['preprocessor']\nridge_model = ridge_best_model.named_steps['ridge']\n\n# Get the transformed feature names from the preprocessor\nfeature_names = preprocessor.transformers_[0][1].get_feature_names_out(categorical_features)\nfeature_names = list(feature_names) + numerical_features\n\n# Get the Ridge model coefficients\nridge_coefficients = ridge_model.coef_\n\n# Create a DataFrame to view coefficients alongside feature names\ncoefficients_df = pd.DataFrame(ridge_coefficients, index=feature_names, columns=['Coefficient'])\n\nprint(coefficients_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                          Coefficient\ncondition_excellent      -1757.428000\ncondition_fair           -9028.934719\ncondition_good             247.778318\ncondition_like new          10.746257\ncondition_new            16184.360080\ncondition_salvage        -5656.521935\ncylinders_10 cylinders   -2174.221101\ncylinders_12 cylinders   28855.332514\ncylinders_3 cylinders    -2561.898216\ncylinders_4 cylinders    -9784.013529\ncylinders_5 cylinders   -10334.000989\ncylinders_6 cylinders    -4662.438622\ncylinders_8 cylinders     -745.954226\ncylinders_other           1407.194169\ntitle_status_clean         593.188501\ntitle_status_lien         2197.695973\ntitle_status_missing      2703.777191\ntitle_status_parts only  -3738.751757\ntitle_status_rebuilt      1182.138648\ntitle_status_salvage     -2938.048555\ntype_SUV                 -3563.091626\ntype_bus                 -1321.462620\ntype_convertible          5972.709233\ntype_coupe                4664.468290\ntype_hatchback           -4482.614339\ntype_mini-van            -8802.778417\ntype_offroad             -1041.271853\ntype_other                5086.725462\ntype_pickup               4936.253388\ntype_sedan               -2976.935159\ntype_truck                4638.686347\ntype_van                 -1151.529263\ntype_wagon               -1959.159444\nyear                      3636.990790\nodometer                 -1465.551715\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 86
    }
  ]
}
